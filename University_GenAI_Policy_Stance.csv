Stance
"If the text generated by ChatGPT is used as a starting point for original research or writing, then it can be a useful tool for generating ideas and suggestions. In this case, it is important to properly cite and attribute the source of the information. ... However, if the text generated by ChatGPT is simply copied and pasted into a paper or report without any modifications, it can be considered plagiarism since the text isn’t original."
"Has ASU considered a ban on AI tools like other institutions such as NYU? No. ASU faculty and administrators are focused on the positive potential of Generative AI while also thinking through concerns about ethics, academic integrity, and privacy. ... What is being done to ensure academic integrity? The Provost’s Office is currently reviewing ASU’s academic integrity policy through the lens of what kind of content can be produced through generative AI and what kind of learning behaviors and outcomes are expected of students. ... Will I get accused of cheating if I use AI tools? Before using AI tools in your coursework, confer with your instructor about their class policy for using AI tools."
"The following sample statements should be taken as starting points to craft your own policy. As of January 23, 2023, the Provost’s Office at BC has not issued a policy regarding the use of AI in coursework. ... Syllabus Statement 1 (Discourage Use of AI) ... Syllabus Statement 2 (Treat AI-generated text as a source)"
"Under BU's guidelines, students can use ChatGPT and other so-called large language models, or LLMs, but must give credit to them whenever they’re used. If students are writing assignments at home, they should include an appendix detailing the entire exchange with an LLM, highlighting the most relevant parts, and write an explanation of exactly how and why the program was used. LLMs shouldn’t be used for in-class tests or assignments, the policy says. Acknowledging the potential difficulty of enforcing or catching improper AI use, the policy says that honesty and fairness will have to be central to how the programs are used. The policy also applies to instructors. Student work that doesn't use AI should be the baseline for grading, it says, with lower potential scores for those who use such programs, especially those who do so extensively. Assignments that simply reuse AI content should get a zero, it says."
"Different faculty will have different expectations about whether and how students can use AI tools, so being transparent about your expectations is essential. If you want to forbid using AI tools, be explicit about this on your syllabus. If you allow these tools, but want them to be acknowledged in the student’s work, explain that on your syllabus and in class."
"While writing performed by an LLM is not necessarily considered copyrighted information, it is still writing the student did not do and therefore fails as certain evidence of student learning outcomes. In the absence of specific university-wide policies, we’ll each have to determine our own means for protecting the integrity of our curriculum while being aware of the opportunities created by new writing technologies."
"AI-generated text has not historically been a part of how educators have thought about plagiarism. Additionally, there is a wide variety of teaching practices now with ChatGPT, with some instructors encouraging student experimentation and others prohibiting its use. Because of changing norms and the wide variety of instructional practice, it is helpful for instructors to be explicit to students about their own expectations."
"“Just like most things we do here at UB, instructors have complete academic freedom to do what they want to do in their classroom,” Ahuna explained. “It is up to individual instructors to determine how it can be used or not used in your courses.” ... Faculty are encouraged to talk with their students early in the semester about whether ChatGPT is acceptable to use in the course."
"If a student uses text generated from ChatGPT and passes it off as their own writing, without acknowledging or citing the influence of ChatGPT in their process, they are in violation of the university’s academic honor code. Lifting full sentences and paragraphs wholecloth ... is considered plagiarism."
"Academic misconduct on exams or other coursework: ... Displaying or using any unauthorized material such as notes, cheat-sheets, or electronic devices, or content generated by artificial intelligence ... Plagiarism: Taking credit for any work not created by the student; work includes, but is not limited to, books, articles, experimental methodology or results, compositions, images, lectures, computer programs, internet postings, and content generated by software or artificial intelligence"
"It is important to note that under the current conditions, using ChatGPT to generate essays for submission for lower division writing will be considered a violation of academic integrity (see sample of lower division writing syllabus text below). However, as with any tool, individual instructors should determine how specific tools are used within their course."
"The UCLA Student Conduct Code states, “Unless otherwise specified by the faculty member, all submissions, whether in draft or final form, to meet course requirements (including a paper, project, exam, computer program, oral presentation, or other work) must either be the Student’s own work, or must clearly acknowledge the source.” Unless an instructor indicates otherwise, the use of ChatGPT or other AI tools for course assignments is akin to receiving assistance from another person and raises the same concern that work is not the student’s own. ... The ultimate decision and responsibility for how to teach about AI and the establishment of or revision of course policies related to its use lies with the instructor."
"For the short term, departments and instructors need to evaluate how problematic ChatGPT is for achieving learning outcomes in their classes. If students can avoid real learning and get high grades on homework assignments by using it, instructors will need to either make assessments “ChatGPT-proof” or find ways to incorporate ChatGPT in helping students to build new skills. It will be impractical to try to ban or prevent the use of ChatGPT. AI tools are here to stay. They will improve and become increasingly important across disciplines."
"How do you know when it is okay to use artificial intelligence (also referred to as ""machines"") and when it’s not? It’s complicated but here are two simple rules of thumb: Is the resource/tool doing the thing for you that is being assessed? ... Is the resource/tool allowed by the course instructor? ... In one course, a professor may allow or invite you to use ChatGPT, but others will prohibit its use. If you use a tool/resource that has been prohibited OR if you use one that is not explicitly allowed, then you might be cheating. If the instructor isn’t clear – ask! Do not assume you can use a tool/resource to do your academic work for you."
"As for the cheating debate, Whitehead suggests that if ChatGPT is able to do an assignment, perhaps the tasks the assignment was asking for were too simple."
Set clear guidelines with your students about what is allowed within the policies of your course. Can your students use ChatGPT (or equivalent) to have questions answered? Is it completely off-limits? Does its use need to be cited in work turned in? ... Consider having the class co-author a policy together after discussion.
"According to CMU’s Office of Community Standards and Integrity, CMU’s academic integrity policy addresses the unauthorized use of such tools. Among the three categories of academic integrity violations (i.e., cheating, plagiarism, and unauthorized assistance), “unauthorized assistance” applies most directly, but the other two may also arguably arise. Specifically, the policy states, “In any manner of presentation, it is the responsibility of each student to produce [their] own original academic work. Collaboration or assistance on academic work to be graded is not permitted unless explicitly authorized by the course instructor(s).”"
"Cheating includes but is not limited to copying from another's work; falsifying problem solutions or laboratory reports; using unauthorized sources, notes or computer programs; or otherwise failing to follow the instructions or procedures in place for a particular testing situation."
"Contract cheating is already a severe problem worldwide, and with the widespread availability of AI writing tools, students can now generate “original” written work for free, without the need to involve a human agent who might betray the student’s confidence. ... As early in your course as possible – ideally within the syllabus itself – you should specify whether, and under what circumstances, the use of AI tools is permissible. ... For all its hazards, ChatGPT also offers promising possibilities."
"""I am really heartened to see all of the innovation and curiosity that's happening at the course level to see how we can use this thing positively to influence students' education,"" said Bryan Smith, the University of Cincinnati's assistant vice provost for faculty advancement and undergraduate affairs."
"It’s plagiarism. It’s also a learning tool. ... Casagrand said the technology itself isn’t plagiarizing—as in directly lifting pre-existing material—but rather is “synthesizing [available material] into novel content.” Zach Herz of Classics said he wondered, given that ChatGPT is built partly on the common academic task of “entering things into computers to generate outputs,” how it substantively differs in impact from technologies like Grammarly, which are commonly used by academics."
"Clarify, in certain terms, when it is NOT OKAY to use those services in your class or on your coursework. Help them understand that using ChatGPT on writing or work that they will submit for credit will result in an academic misconduct issue. ... If there are any acceptable uses, explain those for your students. However, clarify that just because you haven’t forbidden a use, doesn’t mean that it’s okay. In other words, if you haven’t told them that they can use it in a certain way, they can’t use it."
"It is important to be explicit with students about the expectations around the usage of ChatGPT and other AI tools in your course. ... As with all course policies, especially those around academic integrity, it is essential for instructors to be explicit and transparent with their expectations, and to have frank conversations with their students. Additionally, instructors might partner with their students to develop the policies around usage in the course."
"Faculty are encouraged to amend their syllabus to add a statement that explicitly addresses student use of ChatGPT or similar tools use that is consistent with their teaching and learning philosophy. Faculty should be transparent about what students are permitted to use and under what conditions. Faculty might consider requiring students to include brief acknowledgement statements with assignments, ones in which they share (and perhaps reflect on) which tools they used in the process of completing their work. ... The University administration is exploring various AI detection software that faculty could use to identify possible AI generated content."
"Define clear expectations regarding the use of AI tools in your syllabus. This may include tips about the types of issues that may come up in relation to your discipline and your preferred teaching strategies (i.e., the appropriate–or perhaps prohibited–use of AI tools like ChatGPT, etc.), as well as expectations for including attribution when such tools are used. ... The framing of AI as a learning tool is important. As AI tools improve, they are likely to become more and more integrated in how we learn and work. Recognizing that these new tools are not likely going away, how can we enlist the capacities of AI to enhance learning?"
"Faculty across departments are having conversations about how to deal with honor code violations facilitated by ChatGPT, says Vosoughi. Many have broached the issue in their classes, but a coherent policy is not yet in place."
"At least four possible approaches seem plausible: 1. Prohibit all use of these tools 2. Allow their use only with prior permission 3. Allow their use only with explicit acknowledgement 4. Freely allow their use ... Regardless of the approach selected, faculty should explicitly discuss with students the approach and its underlying rationale."
"Vice Provost for Undergraduate Curriculum and Education Steven Weber, PhD, is leading a working group composed mostly of faculty member that is developing guidelines for how faculty should approach AI in the classroom and what anyone in the University, but especially faculty, should be aware of. The goal is for that group to give a presentation to the Office of the Provost by late March or early April."
"Instructors should choose policy language that makes it clear that students should not copy, quote, paraphrase or summarize any source without adequate documentation. ... For any assignments that are meant to be original work, it can be required that students not use AI. ... Students should understand how to cite or give credit to AI generators. They can list ChatGPT as a reference work or quote it within their work. ... There may be cases when instructors either allow or encourage students to use AI for tutoring or help with drafts. It is important to give students guidelines of what is acceptable or not."
"Emory’s honor code states that, “Whenever any idea is taken from a specific work … the student should give credit where credit is due.” Ceijka explained that based on this part of the honor code, the only way a student could ethically use ChatGPT would be if the program was required for a class project. Still, he said that the student would have to “acknowledge that source” and obtain permission from their professor to use the site. “Students should not assume that they can use ChatGPT to write essays,” Ceijka said. ""That is, by definition, plagiarism.”"
ChatGPT’s ability to write human-like text about nearly any topic has led to concerns about the ways that students can use the tool to violate academic integrity policies. There are a few ways that faculty can design assessments to minimize students’ ability and incentives to misuse ChatGPT in writing assignments. Ask for Specifics and References ... Use Recent Events or Material ... Use Offline Material ... Request Personal Impressions ... Break Down Assignments ... It is not recommended that you solely rely on [generative AI] detectors to claim instances of academic misconduct on the part of students.
"Kennedy says the current honor code policy prohibits students from representing any part of another's work as one's own. Students should not present or submit any academic work that impairs the instructor’s ability to accurately assess the student’s academic performance, the code states. “To me, that clearly means if a student is using ChatGPT, they need to cite it and acknowledge it, and mark it in some way in the paper, such as using quotation marks, just like they would with any other material source.” ... Kennedy believes the academic honor code may evolve as the Academic Honor Panel and FSU faculty move forward with this."
"Because some educators worry about a changing social contract in which students submit work they haven’t produced themselves, the first instinct might be to ban ChatGPT use altogether, which some schools have done. Instead of forbidding its use, however, we might investigate which questions AI poses for us as teachers and for our students as learners. ... You may consider adding a statement to your syllabus or even just consider your syllabus in light of AI tools. Different faculty will have different expectations about whether and how students can use AI tools, so being transparent about your expectations is essential. If you want to forbid using AI tools, be explicit about this on your syllabus. ... If you allow these tools but want them to be acknowledged (cited or referenced), explain that on your syllabus."
"Prepare and make time to communicate directly with your students about the ethics of using AI text generators for assignments in your class. In addition to concerns about “cheating,” you should address the learning value that you intend for students to gain from completing your assignments without AI assistance."
"Clarify academic integrity expectations, including whether tools are permitted, permitted with acknowledgement, or prohibited. ... Eventually, higher education’s relationship to AI tools like ChatGPT might look more like the relationship to Wikipedia: something to consider and set parameters around, but not necessarily a fundamental threat to what we do."
"Anticipate [academic dishonesty] by proactively engaging students in an open discussion about academic honesty in your course, including your expectations regarding ChatGPT. Remind students that they are required to follow UGA’s Academic Honesty Policy and talk to your students about how that policy applies to your course. For example, is ChatGPT off-limits, sometimes OK to use, or always encouraged?"
"Faculty may allow the use of ChatGPT and similar technologies in some circumstances (please clarify with your faculty if you have any questions about use). These tools can support learning, and they hold significant promise, so we are eager for students to acquire expertise in their use. ... You must cite your use of these tools appropriately. Not doing so violates the HBS Honor Code, just as would failing to cite any other source."
"Salib said students should learn to use resources like ChatGPT, and that they can contribute to how a student thinks through issues and writes ideas. When it comes to universities making policy, Salib said it becomes more complicated. “There probably shouldn’t be just one policy for all kinds of assignments,” he said. “We probably need something that’s not one size fits all. There should be some kinds of assignments where students are told not to use a language assistant at all, so they develop the chops of writing something from scratch, thinking of something from scratch. There probably should be some assignments for which the requirements are use whatever tools you would like to produce something, but the final product should be more than 70% words you wrote.”"
"Another effective action is to create explicit assignment instructions that address what you view as appropriate uses of AI in each of your assignments and what you view as cheating. ... Since it is a tool and not a source, using chatbots isn't plagiarism. It can be a gray area for students if you haven't specifically addressed it in class or in your syllabus. ... Tell them the consequences for using an AI chatbot moving forward (zeroes, academic integrity violations, etc)."
"Your syllabus should be designed to address ... the importance of academic integrity. Propose alternative assignments or assessments if there is the chance that students might use the tool to misrepresent the output from ChatGPT as their own. Avoid punitive language which can break trust. Stress the positive. Tell them why you are you doing the assignment/assessment, what is the true outcome you are seeking, and how does the assessment help students (and using AI would defeat the desired outcome). ... Do writing assignments in class. It may be useful to have students compose a handwritten essay or write a shorter reflection paper on a current topic in class."
"Most instructors already include statements in their syllabi about academic integrity, so extending those practices to overtly include Chat-GPT and other AI-generated text makes sense."
"You may need to discuss using AI tools in a variety of contexts, including learning materials and campus, collegiate, and course policies related to academic integrity. Consult with your collegiate leadership about specific policies. In any case, providing transparent information about expectations for student use of AI tools and how these expectations align with course goals and scholarly values is crucial."
"Students want to know your expectations for using AI tools in your course. Provide transparent information about your expectations and how these expectations align with course goals and scholarly values. Include information in the syllabus and on assignments, particularly if there is variability in when or how much AI use is allowable. As AI tools become increasingly embedded in existing technologies, students may be in situations where it is unclear how the use of the tool relates to your expectations of them. If the students are unsure, please ask them to contact you for clarification."
"Opinion article rather than official policy or guidance: Use of OpenAI applications can fall under academic integrity policies like plagiarism, but the gray zone between clearly plagiarized work and an academic support tool is large. For example, most instructors would consider it plagiarism for students to ask ChatGPT to write a paper based on a writing prompt from class. But is it OK for students to ask ChatGPT for a summary of research on a topic, which they then use to generate a bibliography as the basis for a research paper they write? ... Discuss with students what is considered acceptable use of AI technologies (e.g., generating a summary of a field) and what is not (e.g., responding to a specific assignment prompt)."
University policy on academic misconduct is broad enough to apply to problematic uses of artificial intelligence. ... We have yet to determine where to set the boundaries of AI use in our classes or our professional lives. That makes it especially important to talk with students about your expectations and to include a statement in your syllabus about those expectations.
"Further, think about your classroom policies and how you might revise them to reflect your teaching values and course outcomes."
"Decide how you want your students to engage or not engage with AI and communicate these expectations clearly and frequently. ... Share both what your policy is and why you have made those decisions. If you are prohibiting them, about the skills students miss out on when they rely on AI-based tools. Discuss why you might have different expectations for using AI-based tools in different assignments or in different capacities."
"The Faculty Senate Rules Committee has made a determination that, absent any guidance from the instructor, the use of ChatCPT and similar AI text generators is prohibited according to the Academic Honesty Policy. Instructors do have the discretion to allow for the use of such tools, however, and must do so explicitly if they want to allow it."
"If the use of such systems is not agreed upon and acknowledged, the practice is analogous to plagiarism. Students will be presenting writing as their own that they did not produce. ... In an educational context, when writing of this sort is not authorized or acknowledged, it does not advance learning goals and makes the evaluation of student achievement difficult or impossible. ... It may be ... that learning how to use AI/LLM technologies to assist writing will be an important or even essential skill. But we are not at this juncture yet, and the core rhetorical skills involving in written and oral communication ... are ones every MIT undergraduate still needs to learn."
"Have discussions with your students about the use of AI text/answer/product generating tools. Set clear guidelines and expectations – explain why you have these guidelines. Include your specific guidelines in course syllabi and assignment instructions. ... Online “AI Detection” programs exist, but they are not well-tested and may not be accurate."
"Discuss academic integrity with students, including what constitutes original work and plagiarism in your field, what type of assistance is and is not permitted. ... These types of apps are not going away and will no doubt proliferate in the future ... so encouraging students to use them productively could be seen as an important contribution to information literacy. For example, consider using ChatGPT as a tool within the writing process."
"Ideally, we would come to a place where this technology can be integrated into our instruction in meaningful ways, in the same way, that over time math teachers integrated calculators into their teaching. ... In the interim, it is probably wise to include some language in your syllabus about the use of this technology and to consider some modifications to your instruction that might help prevent the misuse of ChatGPT."
"Although there are not (yet) new policies about its use per se -- using (e.g. copy/paste) texts or code that is created by ChatGPT, for example, is covered under the UMN Student Conduct Code on Scholastic Dishonesty. ... If you are using it to help analyze texts or using it as a tool -- include information on how you are using it in your assignment. If you are using ChatGPT to help with background research, to create outlines, select keywords, etc. -- you should likely check with your instructor about their class policies."
"May Students Use ChatGPT and Similar Tools for their Academic Work? The answer is, “It depends.” If your professor allows you to use ChatGPT, and you use it as permitted, then you are not committing academic dishonesty. ... However, using ChatGPT on assignments is prohibited if the instructor does not allow its use. Students who use ChatGPT and similar tools without permission, or who use them in improper ways, are violating the academic integrity rules of the University. ... Submitting the words of a chatbot as your own work is likely a form of plagiarism."
"Within a learning environment, the instructor sets the terms for the class. If you want your students to use or avoid Generative AI for various aspects of your course, it’s important to set those expectations clearly. Different instructors will likely take different approaches. You may want to encourage use of A.I. in some contexts ... but ban it in other contexts."
Move away from the five paragraph essay. Chatbots can follow this format easily. Encourage your students' originality by moving away from this formulaic format.
"On Jan. 21, the provost’s office, which is responsible for the administration of academic standards across the university, sent a provisional note offering recommendations for adapting classes to the existence of ChatGPT. The guidelines, which focus on written assignments, give faculty three potential responses: looking for AI use in completed classwork, creating assignments that are difficult to complete with AI or allowing the use of AI for coursework with restrictions. ... While NYU’s academic integrity policy does not explicitly address the use of ChatGPT in coursework, it does prohibit students from violating academic guidelines created by specific schools and departments. It also prohibits students from submitting work that they did not create as their own."
"Due to this rapid growth, universities will need to constantly stay aware of what is going on with ChatGPT and other AI platforms and make updates to their policies at least once a year. Until university leaders develop this guidance, students and faculty should follow the Student Honor Code and Faculty Handbook, and work together to have conversations about expectations in the classroom."
"This semester, I explained in my syllabus that students can’t use autogenerated text without my permission. I also warned them that I may run their responses through a GPT detector and if I discover that they used an AI tool, they’ll have to redo it as a verbal assignment. On the other hand, I have colleagues who teach AI courses and they are actually encouraging their students to use these tools. Personally, I’m not particularly worried about it being an issue, but I wanted to put a statement about it in my syllabus to keep my students from lazily using AI tools as a substitute for real learning."
"Recent advances in AI are so new that educators are just beginning to consider what these new tools might mean for their teaching and their students’ learning. While it may be tempting to focus on potential negative consequences, AI also presents an opportunity to make modifications in our teaching that will improve and personalize student learning, and even to make creative use of the tools that will help prepare students to thrive in the technology enhanced world in which they will live and work."
"Allowing another person or resource (including, but not limited to, generative artificial intelligence) to do one's work and submitting that work under one's own name without proper attribution [is cheating.] ... Plagiarism includes, but is not limited to, the unauthorized use of generative artificial intelligence to create content that is submitted as one's own."
"Different technology is appropriate for different situations and assignments. There may be some where generative AI can be useful, and others where you may want to insist that it not be used. In the latter case, unauthorized use would constitute an act of academic dishonesty. If students are allowed to use ChatGPT to complete an assignment, they should cite it and then explain how they used it and/or how they edited the output, in order to encourage them to be honest about their use."
"What worries or excites you about this new technology from a teaching and learning standpoint? It would be helpful to list the positive and negative implications of something like ChatGPT. If your greatest concern is around academic integrity, for example, you might want to examine your graded activities and assessments for susceptibility. If you are excited about how ChatGPT can be used to evaluate aspects of student writing so you don’t have to, how can you incorporate its use into an assignment?"
"Unless specifically permitted by the professor, and clearly indicated by the student through proper attribution, it is cheating to submit any academic work that originates from another source. ... From sharing notes to the emergence of the internet, generative AI tools, such as ChatGPT, join a long list of technological advancements that have significantly impacted education. When used properly, these resources can aid in a student’s understanding of a particular topic and can be celebrated for the contributions to advancing knowledge. When used improperly, any resource can undercut the purpose and value of academic work."
"Perhaps, for example, if a learning objective is to develop students' own voices and perspective through reflective writing, AI systems would undermine that work. Alternatively, if the goal is to work through writing processes to best structure and refine arguments, an AI system might play a supportive role early in the process. Center a teaching and learning rationale for welcoming or restricting AI use. ... We encourage instructors to have an explicit policy about AI use in the course syllabus, and to reinforce it in conversation with students."
Consider modifying syllabus language to clearly state when and how students can utilize AI tools in course assignments and assessments. Setting clear expectations at the start of the term is essential in providing transparency and clarity with students regarding AI tools.
"Under Penn’s Code of Academic Integrity, students may not use unauthorized assistance in their academic work. It is up to instructors to decide what that means and let students know. While some instructors may consider any use of AI-assisted work to be an academic integrity violation, others may allow students to use AI-generated content in particular instances, such as part of brainstorming, to inform revisions, or for a particular assignment. Some may allow students to use ChatGPT as long as they disclose their use of such tools. Therefore, it’s important to be clear what the policies are for your class or for particular assignments or activities if it will vary."
There seems to currently be two mindsets related to the use of AI in the classroom – ban it or embrace it. Students at other institutions have found themselves in situations where they are accused of violating academic integrity for submitting assignments that were generated by the bot. Some faculty are incorporating into their class assignments so that they can help students to develop the questioning skills needed to maximize on the outputs it produces.
"Because there are no [AI detection] tools that have been proven to be highly accurate yet, they should not be used as plagiarism detectors."
"Princeton University doesn’t intend to ban ChatGPT or to levy a top-down edict about how each instructor should address the AI program in your classes. First, do remember that our Academic Regulations clarify that students are expected to properly acknowledge their sources ... The undergraduate Honor Code and all campus academic integrity rules are quite clear that students must produce original work. ... You might, for example, decide that using AI/ChatGPT violates your collaboration policy, or you might decide it’s appropriate for students to use in certain cases."
"“The institution is not currently monitoring or limiting the use of ChatGPT and I’m not aware of any plans to do so,” said Colin Fewer, dean of Students. ... “From an academic integrity point of view, use of ChatGPT would be treated like more conventional cheating, such as a student paying for someone else to write a paper for them. ... The Academic Integrity Policy gives instructors broad latitude to investigate and make a determination that a student has violated the policy.”"
"The Honor Council sent an email to all undergraduates on April 11, announcing an Honor Code amendment explicitly prohibiting the use of artificial intelligence software such as ChatGPT without proper citation. Additionally, the email clarified professors’ right to ban the use of AI software for their classes. “Utilizing AI software to generate ideas and pass them off as one’s own will also be considered plagiarism and will be adjudicated as such by the Honor Council,” the email said. The email also clarifies that use of AI software “for your own study purposes is allowable.”"
"Under AS&E’s academic honesty policy, giving or receiving unauthorized aid (including unauthorized use of AI tools like ChatGPT) is considered a policy violation. Failing to properly cite sources, including source technologies like ChatGPT, is considered a violation as well. ChatGPT/AI is not automatically considered unauthorized aid; but depending on your course rules, it could be."
"Develop clear policies for each course. For example:
“Use of AI such as ChatGPT is not permitted in any stages of the writing process on any assignment.”
“Use of AI such as ChatGPT is only permitted to help you brainstorm ideas and see examples. All material you submit must be your own.”
“Use of AI such as ChatGPT is fully permitted, but you must cite the tool and be able to explain any work that you submit.”"
"Instructors [should] set their own course policies regarding student use of generative AI. Whatever any given individual instructor decides should be clearly communicated to students in course materials. However, the committee recommends that instructors remind students that the acquisition of academic work in whole or in part from any source (from textbooks and journal articles to web resources to generative AI) and the subsequent presentation of those materials as the student's own work (whether that material is paraphrased or copied in verbatim or near-verbatim form) constitutes an academic integrity violation unless otherwise allowed by the instructor."
"Sheth does allow his prospective students applying for admission into the AI Institute to use the program, however, “but say that you did so. If you can show that you can understand how to effectively use it and use it for the purpose you want,” he said. “Then I’ll think of you being modern and you are aware of what’s happening."""
"Henkel also underscored the utility of USF’s academic integrity policy, which emphasizes honesty, respect and fairness. “I think it’s very important that we set clear expectations about what is and what is not acceptable,” he said. “If the view is that the augmented text violates those things, talk to your students about why you believe that and why you want them to be completing tasks on their own. If there’s opportunities where you want them to be using these tools and build those skill sets, talk about that as well.”"
"Absent a clear statement from a course instructor, use of or consultation with generative AI shall be treated analogously to assistance from another person. In particular, using generative AI tools to substantially complete an assignment or exam (e.g. by entering exam or assignment questions) is not permitted. Students should acknowledge the use of generative AI (other than incidental use) and default to disclosing such assistance when in doubt. Individual course instructors are free to set their own policies regulating the use of generative AI tools in their courses, including allowing or disallowing some or all uses of such tools."
"The panel did not issue a definitive statement on the integrity of ChatGPT. It did give teachers information and guidance on how they should model their own policies towards this new tool. Professors were also told to craft assignments that required thought from students which AI could not replicate. Many professors have already issued statements on the use of AI tools in their syllabi. Some believe AI-generated work is not a student’s own work, while others view it as a tool that should be used but not abused"
"Margaret Usdansky, the founding director for SU’s Center for Learning and Student Success, said SU doesn’t have plans for any significant adjustments of its academic integrity policy or evaluating student work made using ChatGPT. Usdansky said because the university’s academic integrity policy can be made to apply to AI-written work, the current plan is suited to new technologies like ChatGPT. “For now, the policy is broad enough and talks clearly enough about instructors’ ability to set course-specific expectations, and about the assumption that the work you turn in is your own, unless it’s clear from the assignment that it can draw on other sources,” Usdansky said."
"The following guidance is provided to assist you in developing coherent policies on the use of generative 
AI tools in your course. Please adjust the guidance to fit your particular context. Remember also to note 
in specific assignment descriptions where AI use is allowed or disallowed."
"""Plagiarism is using the intellectual property or product of someone else without giving proper credit. The undocumented use of someone else’s words or ideas in any medium of communication (unless such information is recognized as common knowledge) is a serious offense, subject to disciplinary action that may include failure in a course and/or dismissal from the University,"" the code reads. ... How students can use it, according to Anderson and Morey: To produce a quick first draft to get the writing process started. To get a handle on English grammar and structure if it's a second language. To get a grasp on syntax, style and voice."
"Determine your stance on the use of AI tools in your course–will you and your students use it, and if so, what does that look like and what is the rationale? If you choose not to use AI tools in your teaching, be sure to communicate your reasons and rationale clearly and transparently."
"The university is in the process of refreshing our honor code and honor code affirmation to renew our commitment to supporting students in their journey to master complex knowledge and skills. ... Treat ChatGPT as a tool that some students may want to use to help get started writing. For example, students who have difficulty starting writing assignments might be encouraged to generate a paragraph with ChatGPT as a stub that enables them to continue writing. As long as the student ultimately adds significant new material and thoroughly edits or ultimately eliminates the output from ChatGPT, they are producing a document that reflects their own work."
"AI can be used by students as references, tools and even collaborators, but can also be used to avoid doing assigned work. While some instructors may encourage students to use AI resources, others may forbid their use. It’s critical, therefore, to be upfront and clear about how you expect students to interact with AI tools in your course. Students are already experienced adapting to a variety of academic integrity policies in each of their courses since expectations for collaboration, citations and tool use vary class by class."
"Will Tulane ban the chatbot? “No,” Forman said. Instead, Tulane will leave it up to faculty to decide the rules in each class. Some professors have sought to stop students from using it. Others are exploring its values. It is likely students will encounter professors on both sides of the debate this semester. ... Tulane is exploring detecting software with caution because the technology is so new, Forman said. He urged students testing the tool to remain careful."
"Students should seek guidance from their instructors before utilizing AI generative tools for assignments. If students choose to use these tools in some capacity related to creative work, they must make evident any portion of the work generated by the AI tool and which AI tool they used. An individual faculty member may craft specific policies and communicate via syllabi and/or Canvas relating to the use of such tools in their courses. Please note that this is interim guidance as we continue to explore and understand the possibilities and challenges of these tools."
"At Vanderbilt, instructors determine what kinds of outside assistance are allowed or not allowed in their courses. Be clear in your syllabus what tools you expect students to use and how students should engage them. ... If faculty do not expressly tell students that technologies like ChatGPT are allowed, then that technology would fall under the “unauthorized assistance” clause as a possible violation of the honor code."
"As always, instructors should set clear expectations regarding the resources that are permitted in preparing assignments. If students are permitted to use ChatGPT, DALL-E, or similar tools, instructors should provide explicit guidance about how these tools may be used. As always, students must abide by those terms and must properly attribute their sources."
"""Of course, we all 'prohibit' its use for completing assignments. That’s academic dishonesty. But like it or not, this is our new reality and it would be a disservice to our students to ignore it. The foremost fear for educators is that large language models are capable of writing a (good) essay. That’s simply not true. After working with the chatbot, my students realize that now."""
"While most students largely engage in honest behavior in the classroom, some may choose to use tools such as ChatGPT to engage in academic dishonesty. Please continue to be clear in your expectations with your student related to the Undergraduate Honor Code and the use of AI software just as you would other websites that may provide students with means to engage in academic dishonesty. The unauthorized use of ChatGPT and other AI software may fall under several definitions of academic dishonesty in the Undergraduate Honor Code."
"Establish a policy for your course around the use of text generated by AI (e.g., ChatGPT) and communicate this with students through the syllabus and/or assignment prompts. Discuss how you will proceed if you discover that a student has turned in AI-generated work. ... If you have prohibited the use of AI-based tools, such as ChatGPT, and suspect that a student has engaged in academic misconduct, you are encouraged to make a report to Community Standards and Student Conduct."
"In all academic work, the ideas and contributions of others must be appropriately acknowledged and work that is presented as original must be, in fact, original. Using an AI-content generator (such as ChatGPT) to complete coursework without proper attribution or authorization is a form of academic dishonesty. If you are unsure about whether something may be plagiarism or academic dishonesty, please contact your instructor to discuss the issue. Faculty, students and administrative staff all share the responsibility of ensuring the honesty and fairness of the intellectual environment at Washington University in St. Louis."
"At WSU, there are several instructors known to our offices who have already chosen to incorporate the use of these AI tools as a part of their pedagogy in brainstorming, to inform revisions, or for the generative steps of a particular assignment. Others may allow students to use ChatGPT only if they disclose their use of such tools. There are other instructors who wish to ban its use on all their class assignments. In all cases, the instructors are well within their rights to choose the best pedagogy for their discipline and specific course context."
"The WSU Office for Teaching and Learning (OTL) has gathered suggestions for using ChatGPT from POD listserv discussions and chats. Here are some ideas to consider: AI (so far) is not very good at scaffolding work from one assignment to another, so any time you can build writing assignments that build on prior work, it's more difficult to rely on AI to produce meaningful content. Topic proposals, intro paragraphs, drafts and revisions, any kind of scaffolding is difficult to fake with AI."
All content generated through the use of ChatGPT is to be understood and identified as “co-authored” by the user and the AI.
"Students should be made aware that using AI chatbots to produce writing for them will hinder their learning in detrimental ways, making tasks in more advanced classes or in their desired profession more difficult to succeed in. ... In these early days, it will be important to frame any course or program policy as a provisional one—as one that is intentional about responding to a shifting landscape where many people have many questions."
"Instructors should be direct and transparent about what tools students are permitted to use, and about the reasons for any restrictions. Yale College already requires that instructors publish policies about academic integrity, and this practice is common in many graduate and professional school courses. If you expect students to avoid the use of AI chatbots when producing their work, add this to your policy."
"Intentional Misrepresentation occurs when a student deliberately uses someone/something else's language, ideas, or other original (not common knowledge) work without acknowledging the source."
































































































































































































































































































































































































































































































































































































































































































































































































































































































































